{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Проект-для-«Викишоп»\" data-toc-modified-id=\"Проект-для-«Викишоп»-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Проект для «Викишоп»</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод:\" data-toc-modified-id=\"Вывод:-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Вывод:</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Тест-на-адекватность-моделей\" data-toc-modified-id=\"Тест-на-адекватность-моделей-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Тест на адекватность моделей</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#Модель-градиентного-бустинга---CatBoost\" data-toc-modified-id=\"Модель-градиентного-бустинга---CatBoost-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>Модель градиентного бустинга - CatBoost</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import nltk \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import re \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "import catboost as cb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выгрузим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except: \n",
    "    df = pd.read_csv('datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "display(df.head(10))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объявим корпус текстов, переведем его в тип юникод:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n"
     ]
    }
   ],
   "source": [
    "corpus = df['text'].values.astype('U')\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объявим лемматизатор и функцию для очистки и лемматизации текстов \"clear_text\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def clear_text(text):\n",
    "    pattern = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    clear = pattern.split()\n",
    "    lemm = []\n",
    "    for i in range(len(clear)):\n",
    "        lemm.append(wnl.lemmatize(clear[i]))\n",
    "    return \" \".join(lemm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В цикле применим функцию для очистки и лемматизации текстов \"clear_text\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [01:17<00:00, 2053.39it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(corpus))):\n",
    "    corpus[i] = clear_text(corpus[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим датасет и корпус:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D aww He match this background colour I m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man I m really not trying to edit war It s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Congratulations from me a well use the tool we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sorry if the word nonsense wa offensive to you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  alignment on this subject and which are contra...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  Explanation Why the edits made under my userna...  \n",
       "1  D aww He match this background colour I m seem...  \n",
       "2  Hey man I m really not trying to edit war It s...  \n",
       "3  More I can t make any real suggestion on impro...  \n",
       "4  You sir are my hero Any chance you remember wh...  \n",
       "5  Congratulations from me a well use the tool we...  \n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK  \n",
       "7  Your vandalism to the Matt Shirvington article...  \n",
       "8  Sorry if the word nonsense wa offensive to you...  \n",
       "9  alignment on this subject and which are contra...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 3 columns):\n",
      "text         159571 non-null object\n",
      "toxic        159571 non-null int64\n",
      "lemm_text    159571 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_corpus = pd.DataFrame(corpus)\n",
    "df['lemm_text'] = df_corpus[0]\n",
    "display(df.head(10))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим количество объектов мажорного и минорного классов и для наглядности строим график:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    143346\n",
      "1     16225\n",
      "Name: toxic, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f857e0d6c90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df['toxic'].value_counts())\n",
    "zeroes = df['toxic'].value_counts()[0]\n",
    "ones = df['toxic'].value_counts()[1]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.countplot(x='toxic', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем признаки и целевой признак, разделяем датасет на тренировочную и тестовую выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df['lemm_text']\n",
    "target = df['toxic']\n",
    "\n",
    "features_train_1, features_test_1, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=42, stratify = target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем стоп-слова и векторизацию текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nltk.download('stopwords')\n",
    "except:\n",
    "    pass\n",
    "#Объявляю набор стоп-слов \n",
    "try:\n",
    "    stopwords = set(stopwords.words('english'))\n",
    "except:\n",
    "    pass\n",
    "#Объявляю TFIDF-векторизатор\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords) \n",
    "#Выполняю векторизацию текстов\n",
    "features_train = count_tf_idf.fit_transform(features_train_1)\n",
    "features_test = count_tf_idf.transform(features_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцениваем результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119678, 139462)\n",
      "(39893, 139462)\n",
      "(119678,)\n",
      "(39893,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_test.shape)\n",
    "print(target_train.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отдельно слелаем набор фичей и таргетов для обучения CatBoost с меньшим количеством так как CatBoost у меня падал с Dead Kernel из-за перегрузки ядра,при обучении модели пришлось уменьшить количество строк в десятки раз, чтобы хоть както обучить модель на локальной машине!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_cb = features_train_1[:900]\n",
    "features_test_cb = features_test_1[:300]\n",
    "target_train_cb = target_train[:900]\n",
    "target_test_cb = target_test[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nltk.download('stopwords')\n",
    "except:\n",
    "    pass\n",
    "#Объявляю набор стоп-слов \n",
    "try:\n",
    "    stopwords = set(stopwords.words('english'))\n",
    "except:\n",
    "    pass\n",
    "#Объявляю TFIDF-векторизатор\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords) \n",
    "#Выполняю векторизацию текстов\n",
    "features_train_cb = count_tf_idf.fit_transform(features_train_cb)\n",
    "features_test_cb = count_tf_idf.transform(features_test_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 7371)\n",
      "(300, 7371)\n",
      "(900,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train_cb.shape)\n",
    "print(features_test_cb.shape)\n",
    "print(target_train_cb.shape)\n",
    "print(target_test_cb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:\n",
    "   На первом этапе произведена загрузка данных и их подготовка для обучения моделей. Для анализа данных и построения модели предоставлен датасет с размеченными данными, содержащий комментарии пользователей к товарам, доступным для приобретения в интернет-магазине «Викишоп». Датасет состоит из 2 столбцов с данными и 159571 строк.\n",
    "   Исходный датасет состоит из следующих столбцов: \n",
    "- text — текст комментария; \n",
    "- toxic — является ли комментарий токсичным (1) или нет (0) \n",
    "- Пропуски в данных отсутствуют.\n",
    "\n",
    "    После открытия датасета и ознакомления с общей информацией объявлен корпус текстов и переведен в тип юникод. Затем тексты были очищены и лемматизированы. \n",
    "    Проверка соотношения классов показала, что в датасете имеет место явный дисбаланс. Мажорный класс составляет лишь 10% от всего датасета. Следовательно этот аспект необходимо будет учесть в дальнейшем при обучении моделей. \n",
    "    Для векторизации текстов был использован TfidfVectorizer(). После векторизации датасет образовал матрицу размером 159571 строк на 164272 столбцов.\n",
    "\n",
    "В итоге полученный датасет разделен на обучающую и тестовые выборки в соотношении 4:1.\n",
    "Можно приступать к обучению моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве моделей будем использовать Логистическую регрессию, Случайный лес и CatBoost классификатор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест на адекватность моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для надлежащей проверки моделей на адекватность, данные константной модели будут набором единиц."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18457757855696372\n"
     ]
    }
   ],
   "source": [
    "const_model = [1 for i in range(len(target_test))]\n",
    "const_f1 = f1_score(target_test.reset_index(drop=True), const_model)\n",
    "print(const_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее качество модели Логистической регрессии на кросс-валидации: 0.7442037383361634\n",
      "CPU times: user 1min 14s, sys: 1min 53s, total: 3min 7s\n",
      "Wall time: 3min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Обучаю и проверяю Логистическую регрессию на кросс-валидации, указываю параметр class_weight = 'balanced'\n",
    "regression = LogisticRegression(fit_intercept=True, \n",
    "                                class_weight='balanced', \n",
    "                                random_state=42,\n",
    "                                solver='liblinear'\n",
    "                               )\n",
    "#Определяю словарь с набором параметров\n",
    "regression_parametrs = {'C': [0.1, 1, 10]}\n",
    "\n",
    "#Применяю GridSearchCV с кросс-валидацией\n",
    "regression_grid = GridSearchCV(regression, regression_parametrs, scoring='f1', cv=3)\n",
    "regression_grid.fit(features_train, target_train)\n",
    "\n",
    "regression.fit(features_train, target_train)\n",
    "regression_cv_score = cross_val_score(regression,features_train, target_train,scoring='f1',cv=3).mean()\n",
    "print('Среднее качество модели Логистической регрессии на кросс-валидации:', regression_cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем оптимальные гиперпараметры и качество модели на кросс-валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10}\n",
      "0.9161026881923703\n",
      "_______________\n",
      "CPU times: user 66.6 ms, sys: 1.59 ms, total: 68.2 ms\n",
      "Wall time: 81.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "regression_params = regression_grid.best_params_\n",
    "regression_score = regression_grid.score(features_train, target_train)\n",
    "print(regression_params)\n",
    "print(regression_score)\n",
    "print('_______________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем Логистическую регрессию на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 s, sys: 16.6 s, total: 28.6 s\n",
      "Wall time: 28.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "regression_model = LogisticRegression(fit_intercept=True,\n",
    "                                class_weight='balanced',\n",
    "                                random_state=42,\n",
    "                                solver='liblinear',\n",
    "                                C=regression_params['C']\n",
    "                               )\n",
    "\n",
    "regression_model.fit(features_train, target_train)\n",
    "regression_model_predictions = regression_model.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем метрику f1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.763\n"
     ]
    }
   ],
   "source": [
    "regression_predictions = regression_model.predict(features_test)\n",
    "regression_f1 = round(f1_score(target_test, regression_predictions), 3) \n",
    "print(regression_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 20s, sys: 0 ns, total: 5min 20s\n",
      "Wall time: 5min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=-1,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': range(4, 8, 2),\n",
       "                         'min_samples_leaf': range(3, 5),\n",
       "                         'min_samples_split': range(2, 6, 2),\n",
       "                         'n_estimators': range(20, 40, 5)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Подбираю оптимальные гиперпараметры для Случайного леса на кросс-валидации, указываю параметр class_weight = 'balanced'\n",
    "forest = RandomForestClassifier(class_weight='balanced', n_jobs=-1 )\n",
    "#Определяю словарь с набором параметров\n",
    "forest_parametrs = { 'n_estimators': range(20, 40, 5),\n",
    "                     'max_depth': range(4, 8, 2),\n",
    "                     'min_samples_leaf': range(3,5),\n",
    "                     'min_samples_split': range(2,6,2)}\n",
    "\n",
    "#Применяю GridSearchCV с кросс-валидацией\n",
    "forest_grid = GridSearchCV(forest, forest_parametrs, scoring='f1', cv=3)\n",
    "forest_grid.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем оптимальные гиперпараметры и качество модели на кросс-валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 35}\n",
      "0.3191659481069217\n",
      "_______________\n",
      "CPU times: user 1.36 s, sys: 0 ns, total: 1.36 s\n",
      "Wall time: 1.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "forest_params = forest_grid.best_params_\n",
    "forest_score = forest_grid.score(features_train, target_train)\n",
    "print(forest_params)\n",
    "print(forest_score)\n",
    "print('_______________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель Случайного леса на оптимальных гиперпараметрах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.83 s, sys: 0 ns, total: 1.83 s\n",
      "Wall time: 1.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "forest_model = RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced',\n",
    "                                     max_depth=forest_params['max_depth'],\n",
    "                                     min_samples_leaf = forest_params['min_samples_leaf'],\n",
    "                                     min_samples_split = forest_params['min_samples_split'],\n",
    "                                     n_estimators = forest_params['n_estimators'])\n",
    "\n",
    "forest_model.fit(features_train, target_train)\n",
    "forest_model_predictions = forest_model.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем метрику f1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.296\n"
     ]
    }
   ],
   "source": [
    "forest_predictions = forest_model.predict(features_test)\n",
    "forest_f1 =  round(f1_score(target_test, forest_predictions), 3)\n",
    "print(forest_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель градиентного бустинга - CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объявляем модель с учетом дисбаланса классов, пределяем словарь с набором параметров, применяем GridSearchCV с кросс-валидацией:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.329626\n",
      "0:\tlearn: 0.6815956\ttotal: 79.9ms\tremaining: 2.32s\n",
      "10:\tlearn: 0.4700579\ttotal: 433ms\tremaining: 748ms\n",
      "20:\tlearn: 0.3755928\ttotal: 753ms\tremaining: 323ms\n",
      "29:\tlearn: 0.2406593\ttotal: 1.13s\tremaining: 0us\n",
      "Learning rate set to 0.329781\n",
      "0:\tlearn: 0.6588214\ttotal: 12.6ms\tremaining: 366ms\n",
      "10:\tlearn: 0.4517795\ttotal: 375ms\tremaining: 648ms\n",
      "20:\tlearn: 0.3569584\ttotal: 707ms\tremaining: 303ms\n",
      "29:\tlearn: 0.2267826\ttotal: 1.08s\tremaining: 0us\n",
      "Learning rate set to 0.329937\n",
      "0:\tlearn: 0.6709954\ttotal: 12.6ms\tremaining: 365ms\n",
      "10:\tlearn: 0.4559496\ttotal: 378ms\tremaining: 654ms\n",
      "20:\tlearn: 0.3695698\ttotal: 786ms\tremaining: 337ms\n",
      "29:\tlearn: 0.2309431\ttotal: 1.16s\tremaining: 0us\n",
      "Learning rate set to 0.329626\n",
      "0:\tlearn: 0.6796779\ttotal: 193ms\tremaining: 5.58s\n",
      "10:\tlearn: 0.4205947\ttotal: 2.1s\tremaining: 3.62s\n",
      "20:\tlearn: 0.3078062\ttotal: 3.92s\tremaining: 1.68s\n",
      "29:\tlearn: 0.1354610\ttotal: 5.66s\tremaining: 0us\n",
      "Learning rate set to 0.329781\n",
      "0:\tlearn: 0.6561159\ttotal: 165ms\tremaining: 4.8s\n",
      "10:\tlearn: 0.4152326\ttotal: 2.05s\tremaining: 3.55s\n",
      "20:\tlearn: 0.3002147\ttotal: 3.96s\tremaining: 1.7s\n",
      "29:\tlearn: 0.1350431\ttotal: 5.75s\tremaining: 0us\n",
      "Learning rate set to 0.329937\n",
      "0:\tlearn: 0.6628524\ttotal: 138ms\tremaining: 3.99s\n",
      "10:\tlearn: 0.4091778\ttotal: 2.21s\tremaining: 3.81s\n",
      "20:\tlearn: 0.2780311\ttotal: 4.21s\tremaining: 1.8s\n",
      "29:\tlearn: 0.1295144\ttotal: 6.08s\tremaining: 0us\n",
      "Learning rate set to 0.369879\n",
      "0:\tlearn: 0.6510579\ttotal: 18ms\tremaining: 523ms\n",
      "10:\tlearn: 0.4608624\ttotal: 550ms\tremaining: 950ms\n",
      "20:\tlearn: 0.3592140\ttotal: 1.06s\tremaining: 454ms\n",
      "29:\tlearn: 0.2352899\ttotal: 1.55s\tremaining: 0us\n",
      "CPU times: user 24.7 s, sys: 3.39 s, total: 28.1 s\n",
      "Wall time: 35 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=<catboost.core.CatBoostClassifier object at 0x7f8573ca23d0>,\n",
       "             iid='warn', n_jobs=None, param_grid={'depth': [4, 8]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import catboost as cb #Импортирую CatBoost т.к. даже при стартовом инстале иногда пакет слетает\n",
    "\n",
    "#Объявляю модель с учетом дисбаланса классов\n",
    "cb = cb.CatBoostClassifier(class_weights=[1, zeroes/ones], iterations=30)\n",
    "#Определяю словарь с набором параметров\n",
    "cb_parametrs = {'depth': [4, 8]}\n",
    "\n",
    "cb_grid = GridSearchCV(cb, cb_parametrs, scoring='f1', cv=3)\n",
    "cb_grid.fit(features_train_cb, target_train_cb, verbose=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost у меня падал с Dead Kernel из-за перегрузки ядра,при обучении модели пришлось уменьшить количество строк в десятки раз, чтобы хоть както обучить модель на локальной машине!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем оптимальные гиперпараметры и качество модели на кросс-валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'depth': 4}\n",
      "0.9528795811518325\n",
      "_______________\n",
      "CPU times: user 61.2 ms, sys: 8.34 ms, total: 69.5 ms\n",
      "Wall time: 52.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cb_params = cb_grid.best_params_\n",
    "cb_score = cb_grid.score(features_train_cb, target_train_cb)\n",
    "print(cb_params)\n",
    "print(cb_score)\n",
    "print('_______________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель на оптимальных гиперпараметрах и определяем метрику f1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.234635\n",
      "0:\tlearn: 0.6616787\ttotal: 19.5ms\tremaining: 953ms\n",
      "10:\tlearn: 0.5150977\ttotal: 547ms\tremaining: 1.94s\n",
      "20:\tlearn: 0.4485751\ttotal: 1.13s\tremaining: 1.56s\n",
      "30:\tlearn: 0.3813302\ttotal: 1.63s\tremaining: 999ms\n",
      "40:\tlearn: 0.2767559\ttotal: 2.19s\tremaining: 481ms\n",
      "49:\tlearn: 0.2163659\ttotal: 2.7s\tremaining: 0us\n",
      "0.593\n",
      "CPU times: user 2.93 s, sys: 674 ms, total: 3.61 s\n",
      "Wall time: 4.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import catboost as cb #Импортирую CatBoost т.к. даже при стартовом инстале иногда пакет слетает\n",
    "\n",
    "cb_model = cb.CatBoostClassifier(class_weights=[1, zeroes/ones], depth=cb_params['depth'], iterations=50)\n",
    "cb_model.fit(features_train_cb, target_train_cb, verbose=10)\n",
    "cb_model_predictions = cb_model.predict(features_test_cb)\n",
    "\n",
    "cb_f1 = round(f1_score(target_test_cb, cb_model_predictions), 3)\n",
    "print(cb_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим итоговую таблицу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>Время работы модели, сек.</th>\n",
       "      <th>f1-мера</th>\n",
       "      <th>Качество по отношению к константной модели, %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Константная модель</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184578</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.763000</td>\n",
       "      <td>413.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Случайный лес</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>160.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>321.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Модель  Время работы модели, сек.   f1-мера  \\\n",
       "0       Константная модель                        0.0  0.184578   \n",
       "1  Логистическая регрессия                       26.1  0.763000   \n",
       "2            Случайный лес                        2.5  0.296000   \n",
       "3        CatBoostRegressor                        4.6  0.593000   \n",
       "\n",
       "   Качество по отношению к константной модели, %  \n",
       "0                                         100.00  \n",
       "1                                         413.38  \n",
       "2                                         160.37  \n",
       "3                                         321.27  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = ['Модель', 'Время работы модели, сек.', 'f1-мера']\n",
    "const_model = ['Константная модель', 0, const_f1]\n",
    "regression_model = ['Логистическая регрессия', 26.1, regression_f1]\n",
    "forest_model = ['Случайный лес', 2.5, forest_f1]\n",
    "cd_model = ['CatBoostRegressor', 4.6, cb_f1]\n",
    "\n",
    "table = pd.DataFrame([const_model, regression_model, forest_model, cd_model], columns = columns)\n",
    "table['Качество по отношению к константной модели, %'] = round((table['f1-мера']/const_f1) * 100, 2)\n",
    "\n",
    "display(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    На первом этапе произведена загрузка данных и их подготовка для обучения моделей. \n",
    "    Для анализа данных и построения модели предоставлен датасет с размеченными данными, содержащий комментарии пользователей к товарам, доступным для приобретения в интернет-магазине «Викишоп». Датасет состоит из 2 столбцов с данными и 159571 строк. \n",
    "    Затем тексты комментариев были очищены и лемматизированы. \n",
    "    Проверка соотношения классов показала, что в датасете имеет место явный дисбаланс. Мажорный класс составляет лишь 10% от всего датасета. \n",
    "    После векторизации датасет образовал матрицу размером 159571 строк на 164272 столбцов. В итоге полученный датасет разделен на обучающую и тестовые выборки в соотношении 4:1.\n",
    "\n",
    "    В качестве моделей использованы Логистическая регрессия, Случайный лес и CatBoost классификатор. \n",
    "    По результатам подбора гиперпараметров и обучения моделей наилучший результат показал CatBoost классификатор, наихудший - Случайный лес. Все выбранные модели прошли проверку на адекватность в сравнении с константной моделью. Результаты сведены в таблицу. Стоит отметить, что CatBoost классификатор выполняет расчеты в десятки раз дольше, нежели Логистическая регрессия, полученное при этом значение метрики f1 ниже, чем у Логистической регрессии, возможно при увеличении количества итераций мы получим результат будет стремиться к логистической регрессии и может быть лучше, но и количество времени на обучение мы потратим колосальное.\n",
    "    В связи с этим модели Логистическая регрессия и CatBoost классификатор подходят для решения поставленной задачи. Однако, для экономии времени и вычислителной мощности Логистическая регрессия является оптимальным решением для данной задачи.    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
